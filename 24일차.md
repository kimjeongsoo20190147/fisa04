# 사실(Facts): 어떠한 일들이 있었는지
- ELK(Elaticsearch, Logstash, Kibana)

# 배운점(Lesson Learned): 어떤 점을 배웠는지


- Elastic Search : 검색 엔진이지만, NoSQL 데이터를 저장하여 이들을 검색하기 때문에 NoSQL의 특성 역시 지니고 있음.
    - Elastic은 현재는 문서를 찾거나, 인프라를 모니터링하고, 보안 위협으로부터 보호하려는 전 세계 수천 개의 기업에 검색 솔루션을 제공한다.
    - Elastic Stack은 최근 AI 분야에서도 주목받고 있으며, 특히 RAG(Retrieval Augmented Generation) 시스템에서 중요한 역할을 하고 있다.
        - RAG 시스템은 대규모 언어 모델(LLM)이 신뢰할 수 있는 외부 데이터베이스에서 정보를 검색하여 답변의 정확성과 신뢰성을 높이는 방식이다.
    - Elaticsearch는 강력한 검색 및 색인 기능을 제공하여, LLM이 필요로 하는 정보를 신속하게 검색할 수 있도록 돕는다. 이를 통해 방대한 문서나 로그 데이터를 실시간으로 색인하고 검색하는 기능이 강화되어 AI 기반 검색 및 질문 응답 시스템에서 널리 활용되고 있다.
    - 예를 들어, 기업에서는 Elaticsearch를 활용하야 내부 문서 검색 시스템을 구축하고, AI 챗봇이나 고객 지원 시스템이 보다 정교한 답변을 제공할 수 있도록 RAG 기반의 AI 솔루션을 개발하고 있다.


    - 엘라스틱 서치에서는 하나의 인덱스에 하나의 타입만을 구성할 수 있다.
    - 또한 기본적으로 HTTP를 통해 JSON 형식의 RESTFUL API를 사용한다.


    - Elaticsearch의 장점
        - 1) 오픈 소스 검색 엔진(무료)
        - 2) 전문 검색(Full Text Search)
            - 전문 검색이란, 특정 인덱스나 특정 필드 대신 여러 개의 인덱스나 여러 개의 필드를 함께 색인해서 전체에서 특정 단어가 포함된 문서를 검색하는 것을 의미함.
        - 3) 통계 분석
            - 비정형 로그 데이터를 수집하고 한 곳에 모아 통계 분석을 할 수 있음.
        - 4) 멀티테넌시(Multi-teneancy)
            - 검색할 필드명으로 여러 개의 인덱스를 한번에 조회할 수 있다.
        - 5) 역색인(inverted index)
            - 역색인 구조를 통해서 특정 단어를 찾을 때 문서 전체에서 찾는 것이 아닌, 단어가 포함된 특정 문서의 위치를 알아내어 빠르게 결과를 찾아낼 수 있다.
        - 6) 분산 환경
            - Cluster > Node > Shard > Document > field
            - 엘라스틱서치에서는 데이터를 여러 필드로 구성된 도큐먼트라는 JSON 개체로 저장함. 
            - 이 도큐먼트 한 장 한 장은 다시 샤드(shard)라는 작은 단위로 나뉘어 제공하여 데이터를 분산하여 빠르게 처리함.
            - 또한 각 샤드들을 원본과 여러 개의 레플리카(복제본)로 만들어 서로 다른 노드라는 엘라스틱서치의 인스턴스 단위에 나누어 저장함.
            - 이 노드들은 다시 하나의 클러스터 단위로 최종 관리됨.




- 텍스트 분석(Text Analysis)
    - Elastic Search에 저장되는 doc은 모든 문자열(text) 필드별로 역인덱스를 생성하여 문자열 field가 저장될 때 검색어 토큰을 저장하기 위해 거치는 모든 단계를 의미한다.
    - 데이터 입력 -> 필터링 -> 토크나이저 -> 토큰 필터링
    - Analyzer(분석기)
        - Text analysis 과정을 처리하는 기능을 의미한다
        - 구성: Character Filter & Tokenizer & Token Filter
        - 내장 analyzer 종류
            - standard 애널라이저: 기본 애널라이저로, standard 토크나이저와 lowercase 토큰 필터로 이루어져 있음.
            - whitespace 애널라이저: whitespace 토크나이저로 이루어져 있음. 즉, 공백 문자 단위로 토큰을 분리
            - stop 애널라이저: standard 애널라이저와 동일하지만, stop 토큰 필터를 사용하여 불용어를 제거
            - keyword 애널라이저: keyword 토크나이저로 이루어져 있음. 분석을 수행하지 않고 하나의 큰 토큰으로 반환
            - figerprint 애널라이저: 특수한 핑거 프린트 토큰을 생성하여 중복 검사에 사용됨. standard 토크나이저 후 lowercase 토큰 필터, ASCII folding 토큰 필터, stop 토큰 필터 및 fingerprint 토큰 필터를 순서대로 적용.
                - stop 토큰 필터를 기본적으로 비활성화 되어 있음.
                - ASCII folding 토큰 필터는 ASCII에 포함되지 않지만 ASCII 내에 동일한 문자가 있는 경우 동일한 ASCII 문자로 대체함.
                - fingerprint 토큰 필터는 토큰을 정렬하고 중복을 제거하여 하나의 큰 토큰으로 결합함.

    - Nomalyzer(노멀라이저)
        - keyword로 지정된 필드에 들어온 문자열 값을 여러 토큰으로 쪼개지 않고 역색인을 구성함.
        - 그래도 일부 전처리를 하고 싶다면 mapping : { properties: {}}로 필드를 분리하면 됨. 